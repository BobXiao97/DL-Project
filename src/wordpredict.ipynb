{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "dxjnqw3MrWik",
    "outputId": "073c3881-32ea-4146-d5bf-2dbc049e144d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nThis is a sample notebook which basically derives from https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/\\nThe idea of having it here is to see a few important aspects such as:-\\n1. Truncated BPPT\\n2. Simple NLG where at the time of testing, we would ignore all the tokens that are part of input and generate only after that\\n3. Uses a LSTM for the process. A good idea may be to replace it with the Transformer\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a sample notebook which basically derives from https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/\n",
    "The idea of having it here is to see a few important aspects such as:-\n",
    "1. Truncated BPPT\n",
    "2. Simple NLG where at the time of testing, we would ignore all the tokens that are part of input and generate only after that\n",
    "3. Uses a LSTM for the process. A good idea may be to replace it with the Transformer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "filMLyyJjld1",
    "outputId": "553599b4-fd4c-45cf-8303-35e93dd42a94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Data'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Mulie23/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr-jpH65j168",
    "outputId": "6f134e0a-8146-4f6c-80b3-fe7c149dbc95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Data\n"
     ]
    }
   ],
   "source": [
    "cd /content/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HPqjOOacL567"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-iu2-gjMDLl",
    "outputId": "8d84f965-1a5a-41a2-940b-133e83ad44dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read pickle file\n",
    "pickle_in = open(\"plots_text.pickle\",\"rb\")\n",
    "movie_plots = pickle.load(pickle_in)\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(movie_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "9xmt9JZWMpMY",
    "outputId": "0ff6e04b-9e6f-4595-caef-d450fd09e68a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'barry is a private with the 101st airborne division of the united states army, stationed at fort campbell, kentucky. calpernia works as a showgirl at a transgender revue in nashville, tennessee when the two met in 1999. barry\\'s roommate justin fisher  brings barry to the club where she performs. when barry and calpernia begin seeing each other regularly, fisher begins spreading rumors on base about their relationship, which appeared to be a violation of the military\\'s \"don\\'t ask, don\\'t tell\" policy about discussing the sexual orientation of military personnel. barry faces increasing harassment and pressure, which explode into violence over fourth of july weekend. while calpernia performs in a pageant in nashville, barry is beaten to death in his sleep with a baseball bat by calvin glover, who had been goaded by fisher into committing the crime. the film ends with a discussion of the aftermath.'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_plots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1nLwoC4rNhH3"
   },
   "outputs": [],
   "source": [
    "movie_plots = [re.sub(\"[^a-z ' ]\", \" \", i) for i in movie_plots] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "evw4RJ36Nv4g",
    "outputId": "320c9243-e73d-4303-8cdd-e607d270fd55"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"barry is a private with the    st airborne division of the united states army  stationed at fort campbell  kentucky  calpernia works as a showgirl at a transgender revue in nashville  tennessee when the two met in       barry's roommate justin fisher  brings barry to the club where she performs  when barry and calpernia begin seeing each other regularly  fisher begins spreading rumors on base about their relationship  which appeared to be a violation of the military's  don't ask  don't tell  policy about discussing the sexual orientation of military personnel  barry faces increasing harassment and pressure  which explode into violence over fourth of july weekend  while calpernia performs in a pageant in nashville  barry is beaten to death in his sleep with a baseball bat by calvin glover  who had been goaded by fisher into committing the crime  the film ends with a discussion of the aftermath \""
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_plots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uNGppVIPN46v"
   },
   "outputs": [],
   "source": [
    "def get_fixed_sequence(text, seq_len = 5):\n",
    "  sequences = []\n",
    "  words = text.split()\n",
    "  if len(words) > seq_len:\n",
    "    for i in range(seq_len, len(words)):\n",
    "      seq_list = words[i-seq_len: i]\n",
    "      sequences.append(\" \".join(seq_list))\n",
    "  else:\n",
    "    sequences = words\n",
    "  return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhKRVN0BO5IY",
    "outputId": "04e5b839-d6fc-4b2c-90fe-cb5adb5ce26f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning this is mr', 'morning this is mr prabhakar']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fixed_sequence('good morning this is mr prabhakar this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "13f6VtT1PapJ"
   },
   "outputs": [],
   "source": [
    "seqs = [get_fixed_sequence(plot) for plot in movie_plots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1DFyJgDRXRD",
    "outputId": "4dd2234b-ad7e-414f-9fa2-1b72a513feba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QIUvrmqvRaQ5"
   },
   "outputs": [],
   "source": [
    "seqs = sum(seqs, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4lMsHYyNTqTQ",
    "outputId": "6a544e7b-982f-478a-bcce-d8029952c748"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'is a private with the'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0BVQbSthTrbO"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for seq in seqs:\n",
    "  words = seq.split()\n",
    "  x.append(\" \".join(words[:-1]))\n",
    "  y.append(\" \".join(words[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LakvnIF-UMdb",
    "outputId": "f152a802-b7b4-4e6b-d521-d1021cc184fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('barry is a private', 'is a private with')"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNrk79giUNZ8",
    "outputId": "5c362e3a-1cd6-4204-bf0e-032b74999262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10364, 'decapitate')"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create integer-to-token mapping\n",
    "int2token = {}\n",
    "cnt = 0\n",
    "\n",
    "for w in set(\" \".join(movie_plots).split()):\n",
    "  int2token[cnt] = w\n",
    "  cnt+= 1\n",
    "\n",
    "# create token-to-integer mapping\n",
    "token2int = {t: i for i, t in int2token.items()}\n",
    "\n",
    "token2int[\"the\"], int2token[14271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "talm7v_MUZ8V",
    "outputId": "0ae342bc-07e3-4e30-8dc1-ca527a78a827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16120"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set vocabulary size\n",
    "vocab_size = len(int2token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Fb7ALPtdUk0h"
   },
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "  return [token2int[w] for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x_int = [get_integer_seq(i) for i in x]\n",
    "y_int = [get_integer_seq(i) for i in y]\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "x_int = np.array(x_int)\n",
    "y_int = np.array(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiai9h7wUwQf",
    "outputId": "846ec032-5123-43c5-eb9e-0d47805f1264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1750, 14936, 11973,  6577])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gFXCnhJhUx23"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "  prev = 0\n",
    "  for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "    x = arr_x[prev:n]\n",
    "    y = arr_y[prev:n]\n",
    "    prev = n\n",
    "    yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "A7y2Q443VURm"
   },
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, 200)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(200, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # if GPU is available\n",
    "        if (torch.cuda.is_available()):\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        # if GPU is not available\n",
    "        else:\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8U88ZIBEVpG2",
    "outputId": "971d9b6e-eb38-4347-b8ee-e34955a45164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordLSTM(\n",
      "  (emb_layer): Embedding(16120, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=16120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "net = WordLSTM()\n",
    "\n",
    "# push the model to GPU (avoid it if you are not using the GPU)\n",
    "net.cuda()\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zaCylrZcVx7e"
   },
   "outputs": [],
   "source": [
    "def train(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(x_int, y_int, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1))\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2jGtpweWVOr",
    "outputId": "5609a75c-812a-4e79-9842-945171363748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Step: 256...\n",
      "Epoch: 1/20... Step: 512...\n",
      "Epoch: 1/20... Step: 768...\n",
      "Epoch: 1/20... Step: 1024...\n",
      "Epoch: 1/20... Step: 1280...\n",
      "Epoch: 1/20... Step: 1536...\n",
      "Epoch: 1/20... Step: 1792...\n",
      "Epoch: 1/20... Step: 2048...\n",
      "Epoch: 1/20... Step: 2304...\n",
      "Epoch: 1/20... Step: 2560...\n",
      "Epoch: 1/20... Step: 2816...\n",
      "Epoch: 1/20... Step: 3072...\n",
      "Epoch: 1/20... Step: 3328...\n",
      "Epoch: 1/20... Step: 3584...\n",
      "Epoch: 1/20... Step: 3840...\n",
      "Epoch: 1/20... Step: 4096...\n",
      "Epoch: 1/20... Step: 4352...\n",
      "Epoch: 1/20... Step: 4608...\n",
      "Epoch: 2/20... Step: 4864...\n",
      "Epoch: 2/20... Step: 5120...\n",
      "Epoch: 2/20... Step: 5376...\n",
      "Epoch: 2/20... Step: 5632...\n",
      "Epoch: 2/20... Step: 5888...\n",
      "Epoch: 2/20... Step: 6144...\n",
      "Epoch: 2/20... Step: 6400...\n",
      "Epoch: 2/20... Step: 6656...\n",
      "Epoch: 2/20... Step: 6912...\n",
      "Epoch: 2/20... Step: 7168...\n",
      "Epoch: 2/20... Step: 7424...\n",
      "Epoch: 2/20... Step: 7680...\n",
      "Epoch: 2/20... Step: 7936...\n",
      "Epoch: 2/20... Step: 8192...\n",
      "Epoch: 2/20... Step: 8448...\n",
      "Epoch: 2/20... Step: 8704...\n",
      "Epoch: 2/20... Step: 8960...\n",
      "Epoch: 2/20... Step: 9216...\n",
      "Epoch: 2/20... Step: 9472...\n",
      "Epoch: 3/20... Step: 9728...\n",
      "Epoch: 3/20... Step: 9984...\n",
      "Epoch: 3/20... Step: 10240...\n",
      "Epoch: 3/20... Step: 10496...\n",
      "Epoch: 3/20... Step: 10752...\n",
      "Epoch: 3/20... Step: 11008...\n",
      "Epoch: 3/20... Step: 11264...\n",
      "Epoch: 3/20... Step: 11520...\n",
      "Epoch: 3/20... Step: 11776...\n",
      "Epoch: 3/20... Step: 12032...\n",
      "Epoch: 3/20... Step: 12288...\n",
      "Epoch: 3/20... Step: 12544...\n",
      "Epoch: 3/20... Step: 12800...\n",
      "Epoch: 3/20... Step: 13056...\n",
      "Epoch: 3/20... Step: 13312...\n",
      "Epoch: 3/20... Step: 13568...\n",
      "Epoch: 3/20... Step: 13824...\n",
      "Epoch: 3/20... Step: 14080...\n",
      "Epoch: 3/20... Step: 14336...\n",
      "Epoch: 4/20... Step: 14592...\n",
      "Epoch: 4/20... Step: 14848...\n",
      "Epoch: 4/20... Step: 15104...\n",
      "Epoch: 4/20... Step: 15360...\n",
      "Epoch: 4/20... Step: 15616...\n",
      "Epoch: 4/20... Step: 15872...\n",
      "Epoch: 4/20... Step: 16128...\n",
      "Epoch: 4/20... Step: 16384...\n",
      "Epoch: 4/20... Step: 16640...\n",
      "Epoch: 4/20... Step: 16896...\n",
      "Epoch: 4/20... Step: 17152...\n",
      "Epoch: 4/20... Step: 17408...\n",
      "Epoch: 4/20... Step: 17664...\n",
      "Epoch: 4/20... Step: 17920...\n",
      "Epoch: 4/20... Step: 18176...\n",
      "Epoch: 4/20... Step: 18432...\n",
      "Epoch: 4/20... Step: 18688...\n",
      "Epoch: 4/20... Step: 18944...\n",
      "Epoch: 4/20... Step: 19200...\n",
      "Epoch: 5/20... Step: 19456...\n",
      "Epoch: 5/20... Step: 19712...\n",
      "Epoch: 5/20... Step: 19968...\n",
      "Epoch: 5/20... Step: 20224...\n",
      "Epoch: 5/20... Step: 20480...\n",
      "Epoch: 5/20... Step: 20736...\n",
      "Epoch: 5/20... Step: 20992...\n",
      "Epoch: 5/20... Step: 21248...\n",
      "Epoch: 5/20... Step: 21504...\n",
      "Epoch: 5/20... Step: 21760...\n",
      "Epoch: 5/20... Step: 22016...\n",
      "Epoch: 5/20... Step: 22272...\n",
      "Epoch: 5/20... Step: 22528...\n",
      "Epoch: 5/20... Step: 22784...\n",
      "Epoch: 5/20... Step: 23040...\n",
      "Epoch: 5/20... Step: 23296...\n",
      "Epoch: 5/20... Step: 23552...\n",
      "Epoch: 5/20... Step: 23808...\n",
      "Epoch: 5/20... Step: 24064...\n",
      "Epoch: 6/20... Step: 24320...\n",
      "Epoch: 6/20... Step: 24576...\n",
      "Epoch: 6/20... Step: 24832...\n",
      "Epoch: 6/20... Step: 25088...\n",
      "Epoch: 6/20... Step: 25344...\n",
      "Epoch: 6/20... Step: 25600...\n",
      "Epoch: 6/20... Step: 25856...\n",
      "Epoch: 6/20... Step: 26112...\n",
      "Epoch: 6/20... Step: 26368...\n",
      "Epoch: 6/20... Step: 26624...\n",
      "Epoch: 6/20... Step: 26880...\n",
      "Epoch: 6/20... Step: 27136...\n",
      "Epoch: 6/20... Step: 27392...\n",
      "Epoch: 6/20... Step: 27648...\n",
      "Epoch: 6/20... Step: 27904...\n",
      "Epoch: 6/20... Step: 28160...\n",
      "Epoch: 6/20... Step: 28416...\n",
      "Epoch: 6/20... Step: 28672...\n",
      "Epoch: 7/20... Step: 28928...\n",
      "Epoch: 7/20... Step: 29184...\n",
      "Epoch: 7/20... Step: 29440...\n",
      "Epoch: 7/20... Step: 29696...\n",
      "Epoch: 7/20... Step: 29952...\n",
      "Epoch: 7/20... Step: 30208...\n",
      "Epoch: 7/20... Step: 30464...\n",
      "Epoch: 7/20... Step: 30720...\n",
      "Epoch: 7/20... Step: 30976...\n",
      "Epoch: 7/20... Step: 31232...\n",
      "Epoch: 7/20... Step: 31488...\n",
      "Epoch: 7/20... Step: 31744...\n",
      "Epoch: 7/20... Step: 32000...\n",
      "Epoch: 7/20... Step: 32256...\n",
      "Epoch: 7/20... Step: 32512...\n",
      "Epoch: 7/20... Step: 32768...\n",
      "Epoch: 7/20... Step: 33024...\n",
      "Epoch: 7/20... Step: 33280...\n",
      "Epoch: 7/20... Step: 33536...\n",
      "Epoch: 8/20... Step: 33792...\n",
      "Epoch: 8/20... Step: 34048...\n",
      "Epoch: 8/20... Step: 34304...\n",
      "Epoch: 8/20... Step: 34560...\n",
      "Epoch: 8/20... Step: 34816...\n",
      "Epoch: 8/20... Step: 35072...\n",
      "Epoch: 8/20... Step: 35328...\n",
      "Epoch: 8/20... Step: 35584...\n",
      "Epoch: 8/20... Step: 35840...\n",
      "Epoch: 8/20... Step: 36096...\n",
      "Epoch: 8/20... Step: 36352...\n",
      "Epoch: 8/20... Step: 36608...\n",
      "Epoch: 8/20... Step: 36864...\n",
      "Epoch: 8/20... Step: 37120...\n",
      "Epoch: 8/20... Step: 37376...\n",
      "Epoch: 8/20... Step: 37632...\n",
      "Epoch: 8/20... Step: 37888...\n",
      "Epoch: 8/20... Step: 38144...\n",
      "Epoch: 8/20... Step: 38400...\n",
      "Epoch: 9/20... Step: 38656...\n",
      "Epoch: 9/20... Step: 38912...\n",
      "Epoch: 9/20... Step: 39168...\n",
      "Epoch: 9/20... Step: 39424...\n",
      "Epoch: 9/20... Step: 39680...\n",
      "Epoch: 9/20... Step: 39936...\n",
      "Epoch: 9/20... Step: 40192...\n",
      "Epoch: 9/20... Step: 40448...\n",
      "Epoch: 9/20... Step: 40704...\n",
      "Epoch: 9/20... Step: 40960...\n",
      "Epoch: 9/20... Step: 41216...\n",
      "Epoch: 9/20... Step: 41472...\n",
      "Epoch: 9/20... Step: 41728...\n",
      "Epoch: 9/20... Step: 41984...\n",
      "Epoch: 9/20... Step: 42240...\n",
      "Epoch: 9/20... Step: 42496...\n",
      "Epoch: 9/20... Step: 42752...\n",
      "Epoch: 9/20... Step: 43008...\n",
      "Epoch: 9/20... Step: 43264...\n",
      "Epoch: 10/20... Step: 43520...\n",
      "Epoch: 10/20... Step: 43776...\n",
      "Epoch: 10/20... Step: 44032...\n",
      "Epoch: 10/20... Step: 44288...\n",
      "Epoch: 10/20... Step: 44544...\n",
      "Epoch: 10/20... Step: 44800...\n",
      "Epoch: 10/20... Step: 45056...\n",
      "Epoch: 10/20... Step: 45312...\n",
      "Epoch: 10/20... Step: 45568...\n",
      "Epoch: 10/20... Step: 45824...\n",
      "Epoch: 10/20... Step: 46080...\n",
      "Epoch: 10/20... Step: 46336...\n",
      "Epoch: 10/20... Step: 46592...\n",
      "Epoch: 10/20... Step: 46848...\n",
      "Epoch: 10/20... Step: 47104...\n",
      "Epoch: 10/20... Step: 47360...\n",
      "Epoch: 10/20... Step: 47616...\n",
      "Epoch: 10/20... Step: 47872...\n",
      "Epoch: 10/20... Step: 48128...\n",
      "Epoch: 11/20... Step: 48384...\n",
      "Epoch: 11/20... Step: 48640...\n",
      "Epoch: 11/20... Step: 48896...\n",
      "Epoch: 11/20... Step: 49152...\n",
      "Epoch: 11/20... Step: 49408...\n",
      "Epoch: 11/20... Step: 49664...\n",
      "Epoch: 11/20... Step: 49920...\n",
      "Epoch: 11/20... Step: 50176...\n",
      "Epoch: 11/20... Step: 50432...\n",
      "Epoch: 11/20... Step: 50688...\n",
      "Epoch: 11/20... Step: 50944...\n",
      "Epoch: 11/20... Step: 51200...\n",
      "Epoch: 11/20... Step: 51456...\n",
      "Epoch: 11/20... Step: 51712...\n",
      "Epoch: 11/20... Step: 51968...\n",
      "Epoch: 11/20... Step: 52224...\n",
      "Epoch: 11/20... Step: 52480...\n",
      "Epoch: 11/20... Step: 52736...\n",
      "Epoch: 11/20... Step: 52992...\n",
      "Epoch: 12/20... Step: 53248...\n",
      "Epoch: 12/20... Step: 53504...\n",
      "Epoch: 12/20... Step: 53760...\n",
      "Epoch: 12/20... Step: 54016...\n",
      "Epoch: 12/20... Step: 54272...\n",
      "Epoch: 12/20... Step: 54528...\n",
      "Epoch: 12/20... Step: 54784...\n",
      "Epoch: 12/20... Step: 55040...\n",
      "Epoch: 12/20... Step: 55296...\n",
      "Epoch: 12/20... Step: 55552...\n",
      "Epoch: 12/20... Step: 55808...\n",
      "Epoch: 12/20... Step: 56064...\n",
      "Epoch: 12/20... Step: 56320...\n",
      "Epoch: 12/20... Step: 56576...\n",
      "Epoch: 12/20... Step: 56832...\n",
      "Epoch: 12/20... Step: 57088...\n",
      "Epoch: 12/20... Step: 57344...\n",
      "Epoch: 12/20... Step: 57600...\n",
      "Epoch: 13/20... Step: 57856...\n",
      "Epoch: 13/20... Step: 58112...\n",
      "Epoch: 13/20... Step: 58368...\n",
      "Epoch: 13/20... Step: 58624...\n",
      "Epoch: 13/20... Step: 58880...\n",
      "Epoch: 13/20... Step: 59136...\n",
      "Epoch: 13/20... Step: 59392...\n",
      "Epoch: 13/20... Step: 59648...\n",
      "Epoch: 13/20... Step: 59904...\n",
      "Epoch: 13/20... Step: 60160...\n",
      "Epoch: 13/20... Step: 60416...\n",
      "Epoch: 13/20... Step: 60672...\n",
      "Epoch: 13/20... Step: 60928...\n",
      "Epoch: 13/20... Step: 61184...\n",
      "Epoch: 13/20... Step: 61440...\n",
      "Epoch: 13/20... Step: 61696...\n",
      "Epoch: 13/20... Step: 61952...\n",
      "Epoch: 13/20... Step: 62208...\n",
      "Epoch: 13/20... Step: 62464...\n",
      "Epoch: 14/20... Step: 62720...\n",
      "Epoch: 14/20... Step: 62976...\n",
      "Epoch: 14/20... Step: 63232...\n",
      "Epoch: 14/20... Step: 63488...\n",
      "Epoch: 14/20... Step: 63744...\n",
      "Epoch: 14/20... Step: 64000...\n",
      "Epoch: 14/20... Step: 64256...\n",
      "Epoch: 14/20... Step: 64512...\n",
      "Epoch: 14/20... Step: 64768...\n",
      "Epoch: 14/20... Step: 65024...\n",
      "Epoch: 14/20... Step: 65280...\n",
      "Epoch: 14/20... Step: 65536...\n",
      "Epoch: 14/20... Step: 65792...\n",
      "Epoch: 14/20... Step: 66048...\n",
      "Epoch: 14/20... Step: 66304...\n",
      "Epoch: 14/20... Step: 66560...\n",
      "Epoch: 14/20... Step: 66816...\n",
      "Epoch: 14/20... Step: 67072...\n",
      "Epoch: 14/20... Step: 67328...\n",
      "Epoch: 15/20... Step: 67584...\n",
      "Epoch: 15/20... Step: 67840...\n",
      "Epoch: 15/20... Step: 68096...\n",
      "Epoch: 15/20... Step: 68352...\n",
      "Epoch: 15/20... Step: 68608...\n",
      "Epoch: 15/20... Step: 68864...\n",
      "Epoch: 15/20... Step: 69120...\n",
      "Epoch: 15/20... Step: 69376...\n",
      "Epoch: 15/20... Step: 69632...\n",
      "Epoch: 15/20... Step: 69888...\n",
      "Epoch: 15/20... Step: 70144...\n",
      "Epoch: 15/20... Step: 70400...\n",
      "Epoch: 15/20... Step: 70656...\n",
      "Epoch: 15/20... Step: 70912...\n",
      "Epoch: 15/20... Step: 71168...\n",
      "Epoch: 15/20... Step: 71424...\n",
      "Epoch: 15/20... Step: 71680...\n",
      "Epoch: 15/20... Step: 71936...\n",
      "Epoch: 15/20... Step: 72192...\n",
      "Epoch: 16/20... Step: 72448...\n",
      "Epoch: 16/20... Step: 72704...\n",
      "Epoch: 16/20... Step: 72960...\n",
      "Epoch: 16/20... Step: 73216...\n",
      "Epoch: 16/20... Step: 73472...\n",
      "Epoch: 16/20... Step: 73728...\n",
      "Epoch: 16/20... Step: 73984...\n",
      "Epoch: 16/20... Step: 74240...\n",
      "Epoch: 16/20... Step: 74496...\n",
      "Epoch: 16/20... Step: 74752...\n",
      "Epoch: 16/20... Step: 75008...\n",
      "Epoch: 16/20... Step: 75264...\n",
      "Epoch: 16/20... Step: 75520...\n",
      "Epoch: 16/20... Step: 75776...\n",
      "Epoch: 16/20... Step: 76032...\n",
      "Epoch: 16/20... Step: 76288...\n",
      "Epoch: 16/20... Step: 76544...\n",
      "Epoch: 16/20... Step: 76800...\n",
      "Epoch: 16/20... Step: 77056...\n",
      "Epoch: 17/20... Step: 77312...\n",
      "Epoch: 17/20... Step: 77568...\n",
      "Epoch: 17/20... Step: 77824...\n",
      "Epoch: 17/20... Step: 78080...\n",
      "Epoch: 17/20... Step: 78336...\n",
      "Epoch: 17/20... Step: 78592...\n",
      "Epoch: 17/20... Step: 78848...\n",
      "Epoch: 17/20... Step: 79104...\n",
      "Epoch: 17/20... Step: 79360...\n",
      "Epoch: 17/20... Step: 79616...\n",
      "Epoch: 17/20... Step: 79872...\n",
      "Epoch: 17/20... Step: 80128...\n",
      "Epoch: 17/20... Step: 80384...\n",
      "Epoch: 17/20... Step: 80640...\n",
      "Epoch: 17/20... Step: 80896...\n",
      "Epoch: 17/20... Step: 81152...\n",
      "Epoch: 17/20... Step: 81408...\n",
      "Epoch: 17/20... Step: 81664...\n",
      "Epoch: 17/20... Step: 81920...\n",
      "Epoch: 18/20... Step: 82176...\n",
      "Epoch: 18/20... Step: 82432...\n",
      "Epoch: 18/20... Step: 82688...\n",
      "Epoch: 18/20... Step: 82944...\n",
      "Epoch: 18/20... Step: 83200...\n",
      "Epoch: 18/20... Step: 83456...\n",
      "Epoch: 18/20... Step: 83712...\n",
      "Epoch: 18/20... Step: 83968...\n",
      "Epoch: 18/20... Step: 84224...\n",
      "Epoch: 18/20... Step: 84480...\n",
      "Epoch: 18/20... Step: 84736...\n",
      "Epoch: 18/20... Step: 84992...\n",
      "Epoch: 18/20... Step: 85248...\n",
      "Epoch: 18/20... Step: 85504...\n",
      "Epoch: 18/20... Step: 85760...\n",
      "Epoch: 18/20... Step: 86016...\n",
      "Epoch: 18/20... Step: 86272...\n",
      "Epoch: 18/20... Step: 86528...\n",
      "Epoch: 19/20... Step: 86784...\n",
      "Epoch: 19/20... Step: 87040...\n",
      "Epoch: 19/20... Step: 87296...\n",
      "Epoch: 19/20... Step: 87552...\n",
      "Epoch: 19/20... Step: 87808...\n",
      "Epoch: 19/20... Step: 88064...\n",
      "Epoch: 19/20... Step: 88320...\n",
      "Epoch: 19/20... Step: 88576...\n",
      "Epoch: 19/20... Step: 88832...\n",
      "Epoch: 19/20... Step: 89088...\n",
      "Epoch: 19/20... Step: 89344...\n",
      "Epoch: 19/20... Step: 89600...\n",
      "Epoch: 19/20... Step: 89856...\n",
      "Epoch: 19/20... Step: 90112...\n",
      "Epoch: 19/20... Step: 90368...\n",
      "Epoch: 19/20... Step: 90624...\n",
      "Epoch: 19/20... Step: 90880...\n",
      "Epoch: 19/20... Step: 91136...\n",
      "Epoch: 19/20... Step: 91392...\n",
      "Epoch: 20/20... Step: 91648...\n",
      "Epoch: 20/20... Step: 91904...\n",
      "Epoch: 20/20... Step: 92160...\n",
      "Epoch: 20/20... Step: 92416...\n",
      "Epoch: 20/20... Step: 92672...\n",
      "Epoch: 20/20... Step: 92928...\n",
      "Epoch: 20/20... Step: 93184...\n",
      "Epoch: 20/20... Step: 93440...\n",
      "Epoch: 20/20... Step: 93696...\n",
      "Epoch: 20/20... Step: 93952...\n",
      "Epoch: 20/20... Step: 94208...\n",
      "Epoch: 20/20... Step: 94464...\n",
      "Epoch: 20/20... Step: 94720...\n",
      "Epoch: 20/20... Step: 94976...\n",
      "Epoch: 20/20... Step: 95232...\n",
      "Epoch: 20/20... Step: 95488...\n",
      "Epoch: 20/20... Step: 95744...\n",
      "Epoch: 20/20... Step: 96000...\n",
      "Epoch: 20/20... Step: 96256...\n"
     ]
    }
   ],
   "source": [
    "train(net, batch_size = 32, epochs=20, print_every=256)\n",
    "torch.save(net, \"word_predictor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Uemx7F_LlW7X"
   },
   "outputs": [],
   "source": [
    "def predict(net, tkn, h=None):\n",
    "         \n",
    "  # tensor inputs\n",
    "  x = np.array([[token2int[tkn]]])\n",
    "  inputs = torch.from_numpy(x)\n",
    "  \n",
    "  # push to GPU\n",
    "  inputs = inputs.cuda()\n",
    "\n",
    "  # detach hidden state from history\n",
    "  h = tuple([each.data for each in h])\n",
    "\n",
    "  # get the output of the model\n",
    "  out, h = net(inputs, h)\n",
    "\n",
    "  # get the token probabilities\n",
    "  p = F.softmax(out, dim=1).data\n",
    "\n",
    "  p = p.cpu()\n",
    "\n",
    "  p = p.numpy()\n",
    "  p = p.reshape(p.shape[1],)\n",
    "\n",
    "  # get indices of top 3 values\n",
    "  top_n_idx = p.argsort()[-3:][::-1]\n",
    "  # print(top_n_idx)\n",
    "  # randomly select one of the three indices\n",
    "  # sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "  # return the encoded value of the predicted char and the hidden state\n",
    "  list1 = []\n",
    "  for i in top_n_idx:\n",
    "    list1.append(int2token[i])\n",
    "  return list1, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AXb3odAVl5Jy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to generate text\n",
    "def sample(net, prime='it is'):\n",
    "        \n",
    "    # push to GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    # batch size is 1\n",
    "    h = net.init_hidden(1)\n",
    "\n",
    "    toks = prime.split()\n",
    "    # predict next token\n",
    "    for t in prime.split():\n",
    "      try: \n",
    "        token, h = predict(net, t, h)\n",
    "      except:\n",
    "        return \"Some words in the input is not found in our dictionary. Try another sign language word sequence.\"\n",
    "      # print(token)\n",
    "    \n",
    "    # toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    # for i in range(size-1):\n",
    "    #     token, h = predict(net, toks[-1], h)\n",
    "    #     toks.append(token)\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeGe42ehoJZO",
    "outputId": "55bdca97-14c7-4728-bcb4-6eb9baa1e951"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'and', 'are']"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(net, prime = \"dinosaur\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "““NLG_Pytorch_test.ipynb”的副本”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
